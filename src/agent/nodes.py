from typing import Literal

from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage

from src.agent.state import CustomState
from src.agent.utils import (
    initialize_components,
    detect_language,
)
from src.agent.prompts import GRADE_PROMPT, HITL_PROMPT, SYSTEM_PROMPT
from ..core.logger import get_logger

logger = get_logger(__name__)
model, store, retriever_tool = initialize_components()


def language_detection_node(state: CustomState):
    logger.info("ğŸ”¹ [language_detection_node] ì‹œì‘")
    message = str(state.get("messages")[-1].content)
    return {
        "language": detect_language(message)
    }

def route_before_retrieval_node(state: CustomState) -> Literal["retrieve", "rewrite_question"]:
    """
    1. ì§ˆë¬¸ ëª…í™•ì„± í‰ê°€
    2. ë¶ˆëª…í™•í•˜ë©´ rewrite_question(HITL)ë¡œ ì´ë™
    3. ëª…í™•í•˜ë©´ retrieve ê²½ë¡œë¡œ ì§„í–‰ (Tool í˜¸ì¶œ/ë¬¸ì„œ ì¡´ì¬ ì—¬ë¶€ëŠ” ë‚˜ì¤‘ì— íŒë‹¨)
    """
    logger.info("ğŸ”¹ [route_before_retrieval_node] ì‹œì‘")
    message = state.get("messages")[-1]
    question_text = str(message.content).strip()
    
    # 1. ì§ˆë¬¸ ëª…í™•ì„± í‰ê°€
    if not question_text:
        # ë¹ˆ ì§ˆë¬¸ì´ë©´ ë°”ë¡œ HITL
        return "rewrite_question"
    
    # LLMì—ê²Œ ì§ˆë¬¸ í‰ê°€
    eval_prompt = (
        f"ì‚¬ìš©ìê°€ ë³´ë‚¸ ì§ˆë¬¸ì´ ì¶©ë¶„íˆ êµ¬ì²´ì ì´ê³  ëª…í™•í•œê°€ìš”? "
        "yes ë˜ëŠ” noë¡œë§Œ ë‹µí•˜ì„¸ìš”. ë‹¤ë§Œ, ì¡°ê¸ˆ ëª¨í˜¸í•´ë„ yesë¡œ í†µê³¼ì‹œì¼œ ì£¼ì„¸ìš”.\n"
        f"ì§ˆë¬¸: {question_text}"
    )
    eval_response = model.invoke([SystemMessage(content=eval_prompt)])
    unclear = "no" in str(eval_response.content).lower()
    
    if unclear:
        return "rewrite_question"
    
    # ëª…í™•í•˜ë©´ ë°”ë¡œ retrieve ê²½ë¡œ
    return "retrieve"
    

def collect_documents_node(state: CustomState):
    logger.info("ğŸ”¹ [collect_documents_node] ì‹œì‘")

    # ToolNode ë©”ì‹œì§€ í•„í„°ë§
    tool_msgs = [
        msg for msg in state.get("messages", [])
        if getattr(msg, "role", None) == "tool"
    ]

    # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ â†’ ì§ˆë¬¸ì´ ë„ˆë¬´ ëª¨í˜¸í•œ ê²½ìš°
    if not tool_msgs:
        logger.info("No tool outputs found. Redirecting to rewrite_question.")
        return {"next_node": "rewrite_question"}

    collected = []

    for msg in tool_msgs:
        try:
            # retriever_tool ì´ ë°˜í™˜í•œ ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ìˆìŒ
            docs = msg.content   # ì´ë¯¸ [{"content":..., "metadata":...}, ...]
            
            # ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if isinstance(docs, list):
                collected.extend(docs)
            else:
                logger.warning("Tool output is not a list. Skipping.")
        except Exception as e:
            logger.error(f"Failed to parse tool output: {e}")

    # ìµœëŒ€ 3ê°œë§Œ ìœ ì§€ (retriever ê¸°ë³¸ k=3ì´ì§€ë§Œ í˜¹ì‹œ ì¤‘ë³µë„ ëŒ€ë¹„)
    collected = collected[:3]

    logger.info(f"Collected {len(collected)} documents.")

    return {"documents": collected}



def rewrite_question_node(state: CustomState):
    logger.info("ğŸ”¹ [rewrite_question_node] ì‹œì‘")
    logger.info("Rewriting question for HITL...")
    language = state.get("language")
    prompt = HITL_PROMPT.format(language=language)
    response = model.invoke([{"role": "system", "content": prompt}])
    return {"messages": [response]}


def generation_node(state: CustomState):
    logger.info("ğŸ”¹ [generation_node] ì‹œì‘")

    # ì–¸ì–´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    language = state.get("language")
    user_message = state["messages"][-1].content

    # ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    documents = state.get("documents", [])

    # ì–¸ì–´ ì•ˆë‚´ ë©”ì‹œì§€
    language_message = (
        f"Answer the question in {language}. "
        "If en, answer in English; if ko, answer in Korean.\n\n"
    )

    # ë¬¸ì„œ í¬ë§·íŒ…
    formatted_docs = ""
    for idx, doc in enumerate(documents, start=1):
        content = doc.get("content", "")
        url = doc.get("metadata", {}).get("url", "URL ì—†ìŒ")
        formatted_docs += (
            f"   ë¬¸ì„œ {idx}:\n"
            f"       ë‚´ìš©: {content}\n"
            f"       ì¶œì²˜: {url}\n\n"
        )

    # SYSTEM_PROMPTì— ë¬¸ì„œì™€ ì‚¬ìš©ì ì§ˆë¬¸ ì‚½ì…
    system_message = SYSTEM_PROMPT.format(
        documents=formatted_docs,
        input=user_message
    )

    # LLM í˜¸ì¶œ
    final_message = language_message + system_message
    response = model.invoke([SystemMessage(content=final_message)])

    return {"messages": state["messages"] + [response]}



def summarization_node(state: CustomState):
    logger.info("ğŸ”¹ [summarization_node] ì‹œì‘")
    summarization = state.get("summarization")
    logger.info(f"ğŸ”¹ ì´ì „ ìš”ì•½ ê¸¸ì´: {len(summarization)}")

    if summarization:
        summary_message = (
            "This is a summary of the conversation to date:\n\n"
            f"{summarization}\n\n"
            "Extend the summary by taking into account the new messages above:"
        )

    else:
        summary_message = "Create a summary of the conversation above:"

    messages = state.get("messages") + [HumanMessage(content=summary_message)]
    response = model.invoke(messages)

    # Delete all but the 8 most recent messages
    delete_messages = [
        RemoveMessage(id=msg.id) for msg in state.get("messages")[:-8]
    ]
    return {
        "summarization": str(response.content).strip(),
        "messages": delete_messages
    }
